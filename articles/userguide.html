<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="clustermq">
<title>User Guide • clustermq</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="User Guide">
<meta property="og:description" content="clustermq">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-default navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">clustermq</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.9.2</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../articles/userguide.html">User Guide</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../articles/technicaldocs.html">Technical Documentation</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/mschubert/clustermq">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>User Guide</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mschubert/clustermq/blob/HEAD/vignettes/userguide.Rmd" class="external-link"><code>vignettes/userguide.Rmd</code></a></small>
      <div class="d-none name"><code>userguide.Rmd</code></div>
    </div>

    
    
<style type="text/css">
img {
    border: 0px !important;
    margin: 2em 2em 2em 2em !important;
}
code {
    border: 0px !important;
}
</style>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>Install the <code>clustermq</code> package in R from CRAN. This will
automatically detect if <a href="https://github.com/zeromq/libzmq" class="external-link">ZeroMQ</a> is installed and
otherwise use the bundled library:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Recommended:</span></span>
<span><span class="co">#   If your system has `libzmq` installed but you want to enable the worker crash</span></span>
<span><span class="co">#   monitor, set the following environment variable to enable compilation of the</span></span>
<span><span class="co">#   bundled `libzmq` library with the required feature (`-DZMQ_BUILD_DRAFT_API=1`):</span></span>
<span><span class="co"># Sys.setenv(CLUSTERMQ_USE_SYSTEM_LIBZMQ=0)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">'clustermq'</span><span class="op">)</span></span></code></pre></div>
<p>Alternatively you can use the <code>remotes</code> package to install
directly from Github. Note that this version needs
<code>autoconf</code>/<code>automake</code> for compilation:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Sys.setenv(CLUSTERMQ_USE_SYSTEM_LIBZMQ=0)</span></span>
<span><span class="co"># install.packages('remotes')</span></span>
<span><span class="fu">remotes</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">'mschubert/clustermq'</span><span class="op">)</span></span></code></pre></div>
<p>In the <a href="https://github.com/mschubert/clustermq/tree/develop" class="external-link"><code>develop</code></a>
branch, we will introduce code changes and new features. These may
contain bugs, poor documentation, or other inconveniences. This branch
may not install at times. However, <a href="https://github.com/mschubert/clustermq/issues/new" class="external-link">feedback is
very welcome</a>.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Sys.setenv(CLUSTERMQ_USE_SYSTEM_LIBZMQ=0)</span></span>
<span><span class="co"># install.packages('remotes')</span></span>
<span><span class="fu">remotes</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">'mschubert/clustermq'</span>, ref<span class="op">=</span><span class="st">"develop"</span><span class="op">)</span></span></code></pre></div>
<p>For any installation issues please see the <a href="#trouble-install">Troubleshooting</a> section.</p>
</div>
<div class="section level2">
<h2 id="configuration">Configuration<a class="anchor" aria-label="anchor" href="#configuration"></a>
</h2>
<p>Choose your preferred parallelism using:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>clustermq.scheduler <span class="op">=</span> <span class="st">"your scheduler here"</span><span class="op">)</span></span>
<span><span class="co"># this may require additional setup, for details see below</span></span></code></pre></div>
<p>There are three kinds of schedulers:</p>
<ul>
<li>
<code>LOCAL</code> - sequential processing of calls (default if no
HPC scheduler found)</li>
<li><a href="#local-parallelization">Multiple cores on the same
machine</a></li>
<li><a href="#setting-up-the-scheduler">HPC schedulers</a></li>
</ul>
<p>Parallel and HPC schedulers can also be used <a href="#ssh-connector">via SSH</a>.</p>
<p>If this does not work for any reason, please see the <a href="#troubleshooting">Troubleshooting</a> section.</p>
<div class="section level3">
<h3 id="local-parallelization">Local parallelization<a class="anchor" aria-label="anchor" href="#local-parallelization"></a>
</h3>
<p>While this is not the main focus of the package, you can use it to
parallelize function calls locally on multiple cores or processes. This
can also be useful to test your code before submitting it to a
scheduler.</p>
<ul>
<li>Multiprocess (<em>recommended</em>) - Use the <code>callr</code>
package to run and manage multiple parallel R processes with
<code>options(clustermq.scheduler="multiprocess")</code>
</li>
<li>Multicore - Uses the <code>parallel</code> package to fork the
current R process into multiple threads with
<code>options(clustermq.scheduler="multicore")</code>. This sometimes
causes problems (macOS, RStudio) and is not available on Windows.</li>
</ul>
</div>
<div class="section level3">
<h3 id="setting-up-the-scheduler">Setting up the scheduler<a class="anchor" aria-label="anchor" href="#setting-up-the-scheduler"></a>
</h3>
<p>An HPC cluster’s scheduler ensures that computing jobs are
distributed to available worker nodes. Hence, this is what
<code>clustermq</code> interfaces with in order to do computations.</p>
<p>By default, we will take whichever scheduler we find and fall back on
local processing. This will work in most, but not all cases.</p>
<p>To set up a scheduler explicitly, see the following links:</p>
<ul>
<li>
<a href="#LSF">LSF</a> - <em>should work without setup</em>
</li>
<li>
<a href="#SGE">SGE</a> - <em>should work without setup</em>
</li>
<li>
<a href="#SLURM">SLURM</a> - <em>should work without setup</em>
</li>
<li>
<a href="#PBS">PBS</a>/<a href="#TORQUE">Torque</a> - <em>needs</em>
<code>options(clustermq.scheduler="PBS"/"Torque")</code>
</li>
<li>you can suggest another scheduler by <a href="https://github.com/mschubert/clustermq/issues/new" class="external-link">opening an
issue</a>
</li>
</ul>
<p>Default submission templates <a href="https://github.com/mschubert/clustermq/tree/master/inst" class="external-link">are
provided</a> and <a href="#Configuration">can be customized</a>, e.g. to
activate <a href="#Environments">compute environments or
containers</a>.</p>
</div>
<div class="section level3">
<h3 id="ssh-connector">SSH connector<a class="anchor" aria-label="anchor" href="#ssh-connector"></a>
</h3>
<p>There are reasons why you might prefer to not to work on the
computing cluster directly but rather on your local machine instead. <a href="https://posit.co/products/open-source/rstudio/" class="external-link">RStudio</a> is an
excellent local IDE, it’s more responsive than and feature-rich than
browser-based solutions (<a href="https://posit.co/products/open-source/rstudio-server/" class="external-link">RStudio
server</a>, <a href="https://jupyter.org/" class="external-link">Project Jupyter</a>), and it
avoids X forwarding issues when you want to look at plots you just
made.</p>
<p>Using this setup, however, you lost access to the computing cluster.
Instead, you had to copy your data there, and then submit individual
scripts as jobs, aggregating the data in the end again.
<code>clustermq</code> is trying to solve this by providing a
transparent SSH interface.</p>
<p>In order to use <code>clustermq</code> from your local machine, the
package needs to be installed on both there and on the computing
cluster. On the computing cluster, <a href="#setting-up-the-scheduler">set up your scheduler</a> and make sure
<code>clustermq</code> runs there without problems. Note that the
<em>remote scheduler</em> can not be <code>LOCAL</code> (default if no
HPC scheduler found) or <code>SSH</code> for this to work.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># If this is set to 'LOCAL' or 'SSH' you will get the following error:</span></span>
<span><span class="co">#  Expected PROXY_READY, received ‘PROXY_ERROR: Remote SSH QSys is not allowed’</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span></span>
<span>    clustermq.scheduler <span class="op">=</span> <span class="st">"multiprocess"</span> <span class="co"># or multicore, LSF, SGE, Slurm etc.</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>On your <em>local machine</em>, add the following options in your
<code>~/.Rprofile</code>:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span></span>
<span>    clustermq.scheduler <span class="op">=</span> <span class="st">"ssh"</span>,</span>
<span>    clustermq.ssh.host <span class="op">=</span> <span class="st">"user@host"</span>, <span class="co"># use your user and host, obviously</span></span>
<span>    clustermq.ssh.log <span class="op">=</span> <span class="st">"~/cmq_ssh.log"</span> <span class="co"># log for easier debugging</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We recommend that you <a href="https://www.digitalocean.com/community/tutorials/how-to-configure-ssh-key-based-authentication-on-a-linux-server" class="external-link">set
up SSH keys</a> for password-less login.</p>
</div>
</div>
<div class="section level2">
<h2 id="usage">Usage<a class="anchor" aria-label="anchor" href="#usage"></a>
</h2>
<div class="section level3">
<h3 id="the-q-function">The <code>Q</code> function<a class="anchor" aria-label="anchor" href="#the-q-function"></a>
</h3>
<p>The following arguments are supported by <code>Q</code>:</p>
<ul>
<li>
<code>fun</code> - The function to call. This needs to be
self-sufficient (because it will not have access to the
<code>master</code> environment)</li>
<li>
<code>...</code> - All iterated arguments passed to the function. If
there is more than one, all of them need to be named</li>
<li>
<code>const</code> - A named list of non-iterated arguments passed
to <code>fun</code>
</li>
<li>
<code>export</code> - A named list of objects to export to the
worker environment</li>
</ul>
<p>Behavior can further be fine-tuned using the options below:</p>
<ul>
<li>
<code>fail_on_error</code> - Whether to stop if one of the calls
returns an error</li>
<li>
<code>seed</code> - A common seed that is combined with job number
for reproducible results</li>
<li>
<code>memory</code> - Amount of memory to request for the job
(<code>bsub -M</code>)</li>
<li>
<code>n_jobs</code> - Number of jobs to submit for all the function
calls</li>
<li>
<code>job_size</code> - Number of function calls per job. If used in
combination with <code>n_jobs</code> the latter will be overall
limit</li>
<li>
<code>chunk_size</code> - How many calls a worker should process
before reporting back to the master. Default: every worker will report
back 100 times total</li>
</ul>
<p>The full documentation is available by typing <code><a href="../reference/Q.html">?Q</a></code>.</p>
</div>
<div class="section level3">
<h3 id="examples">Examples<a class="anchor" aria-label="anchor" href="#examples"></a>
</h3>
<p>The package is designed to distribute arbitrary function calls on HPC
worker nodes. There are, however, a couple of caveats to observe as the
R session running on a worker does not share your local memory.</p>
<p>The simplest example is to a function call that is completely
self-sufficient, and there is one argument (<code>x</code>) that we
iterate through:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fx</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span> <span class="op">*</span> <span class="fl">2</span></span>
<span><span class="fu"><a href="../reference/Q.html">Q</a></span><span class="op">(</span><span class="va">fx</span>, x<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, n_jobs<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; Running sequentially ('LOCAL') ...</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [1] 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[2]]</span></span>
<span><span class="co">#&gt; [1] 4</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[3]]</span></span>
<span><span class="co">#&gt; [1] 6</span></span></code></pre></div>
<p>Non-iterated arguments are supported by the <code>const</code>
argument:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fx</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="va">x</span> <span class="op">*</span> <span class="fl">2</span> <span class="op">+</span> <span class="va">y</span></span>
<span><span class="fu"><a href="../reference/Q.html">Q</a></span><span class="op">(</span><span class="va">fx</span>, x<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, const<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>y<span class="op">=</span><span class="fl">10</span><span class="op">)</span>, n_jobs<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; Running sequentially ('LOCAL') ...</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [1] 12</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[2]]</span></span>
<span><span class="co">#&gt; [1] 14</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[3]]</span></span>
<span><span class="co">#&gt; [1] 16</span></span></code></pre></div>
<p>If a function relies on objects in its environment that are not
passed as arguments (including other functions), they can be exported
using the <code>export</code> argument:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fx</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="va">x</span> <span class="op">*</span> <span class="fl">2</span> <span class="op">+</span> <span class="va">y</span></span>
<span><span class="fu"><a href="../reference/Q.html">Q</a></span><span class="op">(</span><span class="va">fx</span>, x<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, export<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>y<span class="op">=</span><span class="fl">10</span><span class="op">)</span>, n_jobs<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; Running sequentially ('LOCAL') ...</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [1] 12</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[2]]</span></span>
<span><span class="co">#&gt; [1] 14</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[3]]</span></span>
<span><span class="co">#&gt; [1] 16</span></span></code></pre></div>
<p>If we want to use a package function we need to load it on the worker
using the <code>pkgs</code> parameter, or referencing it with
<code>package_name::</code>:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">f1</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">splitIndices</span><span class="op">(</span><span class="va">x</span>, <span class="fl">3</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/Q.html">Q</a></span><span class="op">(</span><span class="va">f1</span>, x<span class="op">=</span><span class="fl">3</span>, n_jobs<span class="op">=</span><span class="fl">1</span>, pkgs<span class="op">=</span><span class="st">"parallel"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Running sequentially ('LOCAL') ...</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]][[1]]</span></span>
<span><span class="co">#&gt; [1] 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]][[2]]</span></span>
<span><span class="co">#&gt; [1] 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]][[3]]</span></span>
<span><span class="co">#&gt; [1] 3</span></span>
<span></span>
<span><span class="va">f2</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/splitIndices.html" class="external-link">splitIndices</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">3</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/Q.html">Q</a></span><span class="op">(</span><span class="va">f2</span>, x<span class="op">=</span><span class="fl">8</span>, n_jobs<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; Running sequentially ('LOCAL') ...</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]][[1]]</span></span>
<span><span class="co">#&gt; [1] 1 2 3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]][[2]]</span></span>
<span><span class="co">#&gt; [1] 4 5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]][[3]]</span></span>
<span><span class="co">#&gt; [1] 6 7 8</span></span>
<span></span>
<span><span class="co"># Q(f1, x=5, n_jobs=1)</span></span>
<span><span class="co"># (Error #1) could not find function "splitIndices"</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="as-parallel-foreach-backend">As parallel <code>foreach</code> backend<a class="anchor" aria-label="anchor" href="#as-parallel-foreach-backend"></a>
</h3>
<p>The <a href="https://cran.r-project.org/package=foreach" class="external-link"><code>foreach</code></a>
package provides an interface to perform repeated tasks on different
backends. While it can perform the function of simple loops using
<code>%do%</code>:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/RevolutionAnalytics/foreach" class="external-link">foreach</a></span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/foreach/man/foreach.html" class="external-link">foreach</a></span><span class="op">(</span>i<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/foreach/man/foreach.html" class="external-link">%do%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">i</span><span class="op">)</span></span></code></pre></div>
<p>it can also perform these operations in parallel using
<code>%dopar%</code>:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/foreach/man/foreach.html" class="external-link">foreach</a></span><span class="op">(</span>i<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/foreach/man/foreach.html" class="external-link">%dopar%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">i</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: executing %dopar% sequentially: no parallel backend registered</span></span></code></pre></div>
<p>The latter allows registering different handlers for parallel
execution, where we can use <code>clustermq</code>:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># set up the scheduler first, otherwise this will run sequentially</span></span>
<span><span class="fu">clustermq</span><span class="fu">::</span><span class="fu"><a href="../reference/register_dopar_cmq.html">register_dopar_cmq</a></span><span class="op">(</span>n_jobs<span class="op">=</span><span class="fl">2</span>, memory<span class="op">=</span><span class="fl">1024</span><span class="op">)</span> <span class="co"># this accepts same arguments as `Q`</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/foreach/man/foreach.html" class="external-link">foreach</a></span><span class="op">(</span>i<span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/pkg/foreach/man/foreach.html" class="external-link">%dopar%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="co"># this will be executed as jobs</span></span>
<span><span class="co">#&gt; Running sequentially ('LOCAL') ...</span></span></code></pre></div>
<p>As <a href="https://bioconductor.org/packages/release/bioc/html/BiocParallel.html" class="external-link">BiocParallel</a>
supports <code>foreach</code> too, this means we can run all packages
that use <code>BiocParallel</code> on the cluster as well via
<code>DoparParam</code>.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/Bioconductor/BiocParallel" class="external-link">BiocParallel</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/BiocParallel/man/register.html" class="external-link">register</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/BiocParallel/man/DoparParam-class.html" class="external-link">DoparParam</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="co"># after register_dopar_cmq(...)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/BiocParallel/man/bplapply.html" class="external-link">bplapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="va">sqrt</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="with-targets">With <code>targets</code><a class="anchor" aria-label="anchor" href="#with-targets"></a>
</h3>
<p>The <a href="https://github.com/ropensci/targets" class="external-link"><code>targets</code></a>
package enables users to define a dependency structure of different
function calls, and only evaluate them if the underlying data
changed.</p>
<blockquote>
<p>The <code>targets</code> package is a <a href="https://www.gnu.org/software/make/" class="external-link">Make</a>-like pipeline tool
for statistics and data science in R. The package skips costly runtime
for tasks that are already up to date, orchestrates the necessary
computation with implicit parallel computing, and abstracts files as R
objects. If all the current output matches the current upstream code and
data, then the whole pipeline is up to date, and the results are more
trustworthy than otherwise.</p>
</blockquote>
<p>It can use <code>clustermq</code> to <a href="https://books.ropensci.org/targets/hpc.html#clustermq" class="external-link">perform
calculations as jobs</a>.</p>
</div>
</div>
<div class="section level2">
<h2 id="options">Options<a class="anchor" aria-label="anchor" href="#options"></a>
</h2>
<p>The various configurable options are mentioned throughout the
documentation, where applicable, however, we list all of the options
here for reference.</p>
<p>Options can be set by including a call to
<code>options(&lt;key&gt; = &lt;value&gt;)</code> in your
<code>.Rprofile</code>, or by calling
<code>options(&lt;key&gt; = &lt;value&gt;)</code> in a script or
interactively during a session. Note, however, that the latter will not
persist if you restart R.</p>
<ul>
<li>
<code>clustermq.scheduler</code> - One of the supported <a href="#configuration"><code>clustermq</code> schedulers</a>; options are
<code>"LOCAL"</code>, <code>"multiprocess"</code>,
<code>"multicore"</code>, <code>"lsf"</code>, <code>"sge"</code>,
<code>"slurm"</code>, <code>"pbs"</code>, <code>"Torque"</code>, or
<code>"ssh"</code> (default is the HPC scheduler found in
<code>$PATH</code>, otherwise <code>"LOCAL"</code>)</li>
<li>
<code>clustermq.host</code> - The name of the node or device for
constructing the <code>ZeroMQ</code> host address (default is
<code>Sys.info()["nodename"]</code>)</li>
<li>
<code>clustermq.ssh.host</code> - The user name and host for <a href="#ssh-connector">connecting to the HPC via SSH</a>
(e.g. <code>user@host</code>); we recommend setting up SSH keys for
password-less login</li>
<li>
<code>clustermq.ssh.log</code> - Path for a file (on the SSH host)
that will be created and populated with logging information regarding
the SSH connection (e.g. <code>"~/cmq_ssh.log"</code>); helpful for
debugging purposes</li>
<li>
<code>clustermq.ssh.timeout</code> - The amount of time to wait (in
seconds) for a SSH start-up connection before timing out (default is 5
seconds)</li>
<li>
<code>clustermq.worker.timeout</code> - The amount of time to wait
(in seconds) for master-worker communication before timing out (default
is 600 seconds)</li>
<li>
<code>clustermq.error.timeout</code> - The amount of time to wait
(in seconds), in case of a worker error, for the remaining workers to
finish their computations and shut down cleanly (default is
<code>min(timeout, 30)</code> seconds)</li>
<li>
<code>clustermq.template</code> - Path to a <a href="#scheduler-templates">template file</a> for submitting HPC jobs;
only necessary if using your own template, otherwise the default
template will be used (default depends on
<code>clustermq.scheduler</code>)</li>
<li>
<code>clustermq.data.warning</code> - The threshold for the size of
the common data (in Mb) before <code>clustermq</code> throws a warning
(default is 1000)</li>
<li>
<code>clustermq.defaults</code> - A named-list of default values for
the HPC template; this takes precedence over defaults specified in the
template file (default is an empty list (i.e. <code><a href="https://rdrr.io/r/base/list.html" class="external-link">list()</a></code>))</li>
</ul>
</div>
<div class="section level2">
<h2 id="troubleshooting">Troubleshooting<a class="anchor" aria-label="anchor" href="#troubleshooting"></a>
</h2>
<div class="section level3">
<h3 id="trouble-install">Installation errors<a class="anchor" aria-label="anchor" href="#trouble-install"></a>
</h3>
<p>To compile this package a fully C++11 compliant compiler is required.
This is <a href="https://www.tidyverse.org/blog/2023/03/cran-checks-compiled-code/" class="external-link">implicit
for CRAN packages</a> since <code>R=3.6.2</code> and is hence not listed
in <em>SystemRequirements</em>. If you encounter an error saying that
that no matching function call to
<code>zmq::message_t::message_t(std::string&amp;)</code> exists, your
compiler does not (fully) support this.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="ex">In</span> file included from CMQMaster.cpp:2:0:</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="ex">CMQMaster.h:</span> In member function ‘void CMQMaster::proxy_submit_cmd<span class="er">(</span><span class="ex">SEXP,</span> int<span class="kw">)</span><span class="ex">’:</span></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="ex">CMQMaster.h:146:40:</span> error: no matching function for call to ‘zmq::message_t::message_t<span class="er">(</span><span class="ex">std::string</span><span class="kw">&amp;)</span><span class="ex">’</span></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>         <span class="ex">mp.push_back</span><span class="er">(</span><span class="ex">zmq::message_t</span><span class="er">(</span><span class="ex">cur</span><span class="kw">));</span></span></code></pre></div>
<p>This happens for instance for old versions of the <code>gcc</code>
compiler (default on most Linux distributions). You can check your
version in the terminal using:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co"># the minimum required gcc version is 5.5 for full C++11 support (clang 3.3)</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="fu">cc</span> <span class="at">--version</span></span></code></pre></div>
<p>In this case, it is <em>very</em> likely that your HPC system already
has a newer compiler installed that you need to add to your
<code>$PATH</code> or load as a module. Once this is set, you can
install the package from R <em>that was started in a terminal that has
this module/path active</em>.</p>
</div>
<div class="section level3">
<h3 id="trouble-template">Job submission fails with template error<a class="anchor" aria-label="anchor" href="#trouble-template"></a>
</h3>
<p>If you test your setup with a simple <code>Q</code> call, but get an
error like the following:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="sc">&gt;</span> clustermq<span class="sc">::</span><span class="fu">Q</span>(identity, <span class="at">x=</span><span class="dv">1</span>, <span class="at">n_jobs=</span><span class="dv">1</span>)</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>Submitting <span class="dv">1</span> worker <span class="fu">jobs</span> (ID<span class="sc">:</span> cmq6053) ...</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>Unable to run job<span class="sc">:</span> unknown resource <span class="st">"m_mem_free"</span></span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>Exiting.</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a>Your filled job submission template was<span class="sc">:</span></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a><span class="st">#$ -N cmq6053</span></span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a><span class="st">#$ -j y</span></span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a><span class="st">#$ -o /dev/null</span></span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a><span class="st">#$ -cwd</span></span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a><span class="st">#$ -V</span></span>
<span id="cb17-13"><a href="#cb17-13" tabindex="-1"></a><span class="st">#$ -t 1-1</span></span>
<span id="cb17-14"><a href="#cb17-14" tabindex="-1"></a><span class="st">#$ -pe smp 1</span></span>
<span id="cb17-15"><a href="#cb17-15" tabindex="-1"></a><span class="st">#$ -l m_mem_free=1073741824</span></span>
<span id="cb17-16"><a href="#cb17-16" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" tabindex="-1"></a><span class="st">ulimit -v $(( 1024 * 4096 ))</span></span>
<span id="cb17-18"><a href="#cb17-18" tabindex="-1"></a><span class="st">CMQ_AUTH=xxxx R --no-save --no-restore -e 'clustermq:::worker("</span>tcp<span class="sc">:</span><span class="er">//</span><span class="dv">10</span>.<span class="dv">0</span>.<span class="fl">0.100</span><span class="sc">:</span><span class="dv">6053</span><span class="st">")'</span></span>
<span id="cb17-19"><a href="#cb17-19" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb17-20"><a href="#cb17-20" tabindex="-1"></a></span>
<span id="cb17-21"><a href="#cb17-21" tabindex="-1"></a>see<span class="sc">:</span> https<span class="sc">:</span><span class="er">//</span>mschubert.github.io<span class="sc">/</span>clustermq<span class="sc">/</span>articles<span class="sc">/</span>userguide.html<span class="co">#trouble-template</span></span>
<span id="cb17-22"><a href="#cb17-22" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" tabindex="-1"></a>Error <span class="cf">in</span> <span class="fu">initialize</span>(...) <span class="sc">:</span> Job submission failed with error code <span class="dv">1</span></span>
<span id="cb17-24"><a href="#cb17-24" tabindex="-1"></a>In addition<span class="sc">:</span> Warning message<span class="sc">:</span></span>
<span id="cb17-25"><a href="#cb17-25" tabindex="-1"></a>In <span class="fu">system2</span>(<span class="st">"qsub"</span>, <span class="at">input =</span> filled, <span class="at">stdout =</span> <span class="cn">TRUE</span>) <span class="sc">:</span></span>
<span id="cb17-26"><a href="#cb17-26" tabindex="-1"></a>  running command <span class="st">''</span>qsub<span class="st">' &lt; '</span><span class="sc">/</span>tmp<span class="sc">/</span>RtmpdGJOxs<span class="sc">/</span>filee7f3011007b<span class="st">''</span> had status <span class="dv">1</span></span></code></pre></div>
<p>This means that your job submission system has not been successfully
auto-detected and requires some configuration, <em>i.e.</em> you need to
manually specify what scheduler and template you want to use.</p>
<p>Be sure to know which scheduler your HPC provides, and then see the
<a href="#scheduler-templates">manual scheduler setup</a> on how to set
it up.</p>
<p>You may need to change some scheduler-specific options in the
template file for this to work, like the queue/partition name or how to
request memory or runtime. Often, the error message gives you a good
hint on what to change: In the example above, we are using a version of
SGE where we need to use <code>mem_free</code> instead of
<code>m_mem_free</code> to request memory.</p>
<p>If it is not obvious what do change, consult the scheduler
documentation or your system admins for more information. For the
latter, provide them with the filled template from the error message (as
this is an HPC submission template issue rather than a
<code>clustermq</code> package issue).</p>
</div>
<div class="section level3">
<h3 id="trouble-stuck">Session gets stuck at “Running calculations”<a class="anchor" aria-label="anchor" href="#trouble-stuck"></a>
</h3>
<p>Your R session may be stuck at something like the following:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="sc">&gt;</span> clustermq<span class="sc">::</span><span class="fu">Q</span>(identity, <span class="at">x=</span><span class="dv">42</span>, <span class="at">n_jobs=</span><span class="dv">1</span>)</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>Submitting <span class="dv">1</span> worker <span class="fu">jobs</span> (ID<span class="sc">:</span> cmq8480) ...</span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>Running <span class="dv">1</span> <span class="fu">calculations</span> (<span class="dv">5</span> objs<span class="sc">/</span><span class="fl">19.4</span> Kb common; <span class="dv">1</span> calls<span class="sc">/</span>chunk) ...</span></code></pre></div>
<p>You will see this every time your jobs are queued but not yet
started. Depending on how busy your HPC is, this may take a long time.
You can check the queueing status of your jobs in the terminal with
<em>e.g.</em> <code>qstat</code> (SGE), <code>bjobs</code> (LSF), or
<code>sinfo</code> (SLURM).</p>
<p>If your jobs are already finished, this likely means that the
<code>clustermq</code> workers can not connect to the main session. You
can confirm this by passing <a href="#debugging-workers"><code>log_worker=TRUE</code></a> to
<code>Q</code> and inspect the logs created in your current working
directory. If they state something like:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="op">&gt;</span> clustermq:::worker<span class="kw">(</span><span class="st">"tcp://my.headnode:9091"</span><span class="kw">)</span></span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a><span class="ex">2023-12-11</span> 10:22:58.485529 <span class="kw">|</span> <span class="ex">Master:</span> tcp://my.headnode:9091</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a><span class="ex">2023-12-11</span> 10:22:58.488892 <span class="kw">|</span> <span class="ex">connecting</span> to: tcp://my.headnode:9091:</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a><span class="ex">Error:</span> Connection failed after 10016 ms</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a><span class="ex">Execution</span> halted</span></code></pre></div>
<p>the submitted job is indeed unable to establish a network connection
with the head node. This can happen if your HPC does not allow these
connections, but more likely happens because there are multiple network
interfaces, only some of which have access to the head node.</p>
<p>You can list the available network interfaces using the
<code>ifconfig</code> command in the terminal. Find the interface that
shares a subnetwork with the head node and add the <a href="#options">R
option</a> <code>clustermq.host=&lt;interface&gt;</code>. If this is
unclear, contact your system administrators to see which interface to
use.</p>
</div>
<div class="section level3">
<h3 id="debugging-workers">Debugging workers<a class="anchor" aria-label="anchor" href="#debugging-workers"></a>
</h3>
<p>Function calls evaluated by workers are wrapped in event handlers,
which means that even if a call evaluation throws an error, this should
be reported back to the main R session.</p>
<p>However, there are reasons why workers might crash, and in which case
they can not report back. These include:</p>
<ul>
<li>A segfault in a low-level process</li>
<li>Process kill due to resource constraints (e.g. walltime)</li>
<li>Reaching the wait timeout without any signal from the master
process</li>
<li>Probably others</li>
</ul>
<p>In this case, it is useful to have the worker(s) create a log file
that will also include events that are not reported back. It can be
requested using:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/Q.html">Q</a></span><span class="op">(</span><span class="va">...</span>, log_worker<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>This will create a file called <em><cmq_id>-<array_index>.log</array_index></cmq_id></em> in
your current working directory, irrespective of which scheduler you
use.</p>
<p>You can customize the file name using</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="fu">Q</span>(..., <span class="at">template=</span><span class="fu">list</span>(<span class="at">log_file =</span> <span class="sc">&lt;</span>yourlog<span class="sc">&gt;</span>))</span></code></pre></div>
<p>Note that in this case <code>log_file</code> is a template field of
your scheduler script, and hence needs to be present there in order for
this to work. The default templates all have this field included.</p>
<p>In order to log each worker separately, some schedulers support
wildcards in their log file names. For instance:</p>
<ul>
<li>Multicore/Multiprocess:
<code>log_file="/path/to.file.%i"</code>
</li>
<li>SGE: <code>log_file="/path/to.file.\$TASK_ID"</code>
</li>
<li>LSF: <code>log_file="/path/to.file.%I"</code>
</li>
<li>Slurm: <code>log_file="/path/to.file.%a"</code>
</li>
<li>PBS: <code>log_file="/path/to.file.$PBS_ARRAY_INDEX"</code>
</li>
<li>Torque: <code>log_file="/path/to.file.$PBS_ARRAYID"</code>
</li>
</ul>
<p>Your scheduler documentation will have more details about the
available options.</p>
<p>When reporting a bug that includes worker crashes, please always
include a log file.</p>
</div>
<div class="section level3">
<h3 id="ssh">SSH<a class="anchor" aria-label="anchor" href="#ssh"></a>
</h3>
<p>Before trying remote schedulers via SSH, make sure that the scheduler
works when you first connect to the cluster and run a job from
there.</p>
<p>If the terminal is stuck at</p>
<pre><code>Connecting &lt;user@host&gt; via SSH ...</code></pre>
<p>make sure that each step of your SSH connection works by typing the
following commands in your <strong>local</strong> terminal and make sure
that you don’t get errors or warnings in each step:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="co"># test your ssh login that you set up in ~/.ssh/config</span></span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a><span class="co"># if this fails you have not set up SSH correctly</span></span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a><span class="fu">ssh</span> <span class="op">&lt;</span>user@host<span class="op">&gt;</span></span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a><span class="co"># test port forwarding from 54709 remote to 6687 local (ports are random)</span></span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a><span class="co"># if the fails you will not be able to use clustermq via SSH</span></span>
<span id="cb23-7"><a href="#cb23-7" tabindex="-1"></a><span class="fu">ssh</span> <span class="at">-R</span> 54709:localhost:6687 <span class="op">&lt;</span>user@host<span class="op">&gt;</span> R <span class="at">--vanilla</span></span></code></pre></div>
<p>If you get an <code>Command not found: R</code> error, make sure your
<code>$PATH</code> is set up correctly in your
<code>~/.bash_profile</code> and/or your <code>~/.bashrc</code>
(depending on your cluster config you might need either). You may also
need to modify your <a href="#ssh-template">SSH template</a> to load R
as a module or conda environment.</p>
<p>If you get a SSH warning or error try again with <code>ssh -v</code>
to enable verbose output. If the forward itself works, run the following
in your local R session (ideally also in command-line R, <a href="https://github.com/mschubert/clustermq/issues/206" class="external-link">not only in
RStudio</a>):</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>clustermq.scheduler <span class="op">=</span> <span class="st">"ssh"</span>,</span>
<span>        clustermq.ssh.log <span class="op">=</span> <span class="st">"~/ssh_proxy.log"</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/Q.html">Q</a></span><span class="op">(</span><span class="va">identity</span>, x<span class="op">=</span><span class="fl">1</span>, n_jobs<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p>This will create a log file <em>on the remote server</em> that will
contain any errors that might have occurred during
<code>ssh_proxy</code> startup.</p>
<p>If the <code>ssh_proxy</code> startup fails on your local machine
with the error</p>
<pre><code>Remote R process did not respond after 5 seconds. Check your SSH server log.</code></pre>
<p>but the server log does not show any errors, then you can try
increasing the timeout:</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>clustermq.ssh.timeout <span class="op">=</span> <span class="fl">30</span><span class="op">)</span> <span class="co"># in seconds</span></span></code></pre></div>
<p>This can happen when your SSH startup template includes additional
steps before starting R, such as activating a module or conda
environment, or having to confirm the connection via two-factor
authentication.</p>
</div>
</div>
<div class="section level2">
<h2 id="environments">Environments<a class="anchor" aria-label="anchor" href="#environments"></a>
</h2>
<div class="section level3">
<h3 id="environments-for-workers">Environments for workers<a class="anchor" aria-label="anchor" href="#environments-for-workers"></a>
</h3>
<p>In some cases, it may be necessary to activate a specific computing
environment on the scheduler jobs prior to starting up the worker. This
can be, for instance, because <em>R</em> was only installed in a
specific environment or container.</p>
<p>Examples for such environments or containers are:</p>
<ul>
<li>
<a href="https://modules.sourceforge.net/" class="external-link">Bash module</a>
environments</li>
<li>
<a href="https://conda.io/" class="external-link">Conda</a> environments</li>
<li>
<a href="https://www.docker.com/" class="external-link">Docker</a>/<a href="https://singularity.lbl.gov/" class="external-link">Singularity</a> containers</li>
</ul>
<p>It should be possible to activate them in the job submission script
(i.e., the template file). This is widely untested, but would look the
following for the <a href="#LSF">LSF</a> scheduler (analogous for
others):</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a><span class="co">#BSUB-J {{ job_name }}[1-{{ n_jobs }}]  # name of the job / array jobs</span></span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a><span class="co">#BSUB-o {{ log_file | /dev/null }}      # stdout + stderr</span></span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a><span class="co">#BSUB-M {{ memory | 4096 }}             # Memory requirements in Mbytes</span></span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a><span class="co">#BSUB-R rusage[mem={{ memory | 4096 }}] # Memory requirements in Mbytes</span></span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a><span class="co">##BSUB-q default                        # name of the queue (uncomment)</span></span>
<span id="cb27-6"><a href="#cb27-6" tabindex="-1"></a><span class="co">##BSUB-W {{ walltime | 6:00 }}          # walltime (uncomment)</span></span>
<span id="cb27-7"><a href="#cb27-7" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" tabindex="-1"></a><span class="ex">module</span> load {{ bashenv <span class="kw">|</span> <span class="ex">default_bash_env</span> }}</span>
<span id="cb27-9"><a href="#cb27-9" tabindex="-1"></a><span class="co"># or: source activate {{ conda | default_conda_env_name }}</span></span>
<span id="cb27-10"><a href="#cb27-10" tabindex="-1"></a><span class="co"># or: your environment activation command</span></span>
<span id="cb27-11"><a href="#cb27-11" tabindex="-1"></a><span class="bu">ulimit</span> <span class="at">-v</span> <span class="va">$((</span> <span class="dv">1024</span> <span class="op">*</span> <span class="er">{{</span> <span class="va">memory</span> <span class="op">|</span> <span class="dv">4096</span> }} <span class="va">))</span></span>
<span id="cb27-12"><a href="#cb27-12" tabindex="-1"></a><span class="va">CMQ_AUTH</span><span class="op">=</span>{{ <span class="ex">auth</span> }} R <span class="at">--no-save</span> <span class="at">--no-restore</span> <span class="at">-e</span> <span class="st">'clustermq:::worker("{{ master }}")'</span></span></code></pre></div>
<p>This template still needs to be filled, so in the above example you
need to pass either</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/Q.html">Q</a></span><span class="op">(</span><span class="va">...</span>, template<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>bashenv<span class="op">=</span><span class="st">"my environment name"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>or set it via an <em>.Rprofile</em> option:</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span></span>
<span>    clustermq.defaults <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>bashenv<span class="op">=</span><span class="st">"my default env"</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="running-master-inside-containers">Running master inside containers<a class="anchor" aria-label="anchor" href="#running-master-inside-containers"></a>
</h3>
<p>If your master process is inside a container, accessing the HPC
scheduler is more difficult. Containers, including singularity and
docker, isolate the processes inside the container from the host. The
<em>R</em> process will not be able to submit a job because the
scheduler cannot be found.</p>
<p>Note that the HPC node running the master process must be allowed to
submit jobs. Not all HPC systems allow compute nodes to submit jobs. If
that is the case, you may need to run the master process on the login
node, and discuss the issue with your system administrator.</p>
<p>If your container is binary compatible with the host, you may be able
to bind in the scheduler executable to the container.</p>
<p>For example, PBS might look something like:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a><span class="co">#PBS directives ...</span></span>
<span id="cb30-2"><a href="#cb30-2" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" tabindex="-1"></a><span class="ex">module</span> load singularity</span>
<span id="cb30-4"><a href="#cb30-4" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" tabindex="-1"></a><span class="va">SINGULARITYENV_APPEND_PATH</span><span class="op">=</span>/opt/pbs/bin</span>
<span id="cb30-6"><a href="#cb30-6" tabindex="-1"></a><span class="ex">singularity</span> exec <span class="at">--bind</span> /opt/pbs/bin r_image.sif Rscript master_script.R</span></code></pre></div>
<p>A working example of binding SLURM into a CentOS 7 container image
from a CentOS 7 host is available at <a href="https://groups.google.com/a/lbl.gov/d/msg/singularity/syLcsIWWzdo/NZvF2Ud2AAAJ" class="external-link uri">https://groups.google.com/a/lbl.gov/d/msg/singularity/syLcsIWWzdo/NZvF2Ud2AAAJ</a></p>
<p>Alternatively, you can create a script that uses SSH to execute the
scheduler on the login node. For this, you will need an SSH client in
the container, <a href="https://www.digitalocean.com/community/tutorials/how-to-configure-ssh-key-based-authentication-on-a-linux-server" class="external-link">keys
set up for password-less login</a>, and create a script to call the
scheduler on the login node via ssh (e.g. <code>~/bin/qsub</code> for
SGE/PBS/Torque, <code>bsub</code> for LSF and <code>sbatch</code> for
Slurm):</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a><span class="co">#!/bin/bash</span></span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a><span class="fu">ssh</span> <span class="at">-i</span> ~/.ssh/<span class="op">&lt;</span>your key file<span class="op">&gt;</span> <span class="va">${PBS_O_HOST</span><span class="op">:-</span><span class="st">"no_host_not_in_a_pbs_job"</span><span class="va">}</span> qsub <span class="st">"</span><span class="va">$@</span><span class="st">"</span></span></code></pre></div>
<p>Make sure the script is executable, and bind/copy it into the
container somewhere on <code>$PATH</code>. Home directories are bound in
by default in singularity.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a><span class="fu">chmod</span> u+x ~/bin/qsub</span>
<span id="cb32-2"><a href="#cb32-2" tabindex="-1"></a><span class="va">SINGULARITYENV_APPEND_PATH</span><span class="op">=</span>~/bin</span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="scheduler-templates">Scheduler templates<a class="anchor" aria-label="anchor" href="#scheduler-templates"></a>
</h2>
<div class="section level3">
<h3 id="lsf">LSF<a class="anchor" aria-label="anchor" href="#lsf"></a>
</h3>
<p>In your <code>~/.Rprofile</code> on your computing cluster, set the
following options:</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span></span>
<span>    clustermq.scheduler <span class="op">=</span> <span class="st">"lsf"</span>,</span>
<span>    clustermq.template <span class="op">=</span> <span class="st">"/path/to/file/below"</span> <span class="co"># if using your own template</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The option <code>clustermq.template</code> should point to a LSF
template file like the one below (only needed if you want to supply your
own template rather than using the default).</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a><span class="co">#BSUB-J {{ job_name }}[1-{{ n_jobs }}]  # name of the job / array jobs</span></span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a><span class="co">#BSUB-n {{ cores | 1 }}                 # number of cores to use per job</span></span>
<span id="cb34-3"><a href="#cb34-3" tabindex="-1"></a><span class="co">#BSUB-o {{ log_file | /dev/null }}      # stdout + stderr; %I for array index</span></span>
<span id="cb34-4"><a href="#cb34-4" tabindex="-1"></a><span class="co">#BSUB-M {{ memory | 4096 }}             # Memory requirements in Mbytes</span></span>
<span id="cb34-5"><a href="#cb34-5" tabindex="-1"></a><span class="co">#BSUB-R rusage[mem={{ memory | 4096 }}] # Memory requirements in Mbytes</span></span>
<span id="cb34-6"><a href="#cb34-6" tabindex="-1"></a><span class="co">##BSUB-q default                        # name of the queue (uncomment)</span></span>
<span id="cb34-7"><a href="#cb34-7" tabindex="-1"></a><span class="co">##BSUB-W {{ walltime | 6:00 }}          # walltime (uncomment)</span></span>
<span id="cb34-8"><a href="#cb34-8" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" tabindex="-1"></a><span class="bu">ulimit</span> <span class="at">-v</span> <span class="va">$((</span> <span class="dv">1024</span> <span class="op">*</span> <span class="er">{{</span> <span class="va">memory</span> <span class="op">|</span> <span class="dv">4096</span> }} <span class="va">))</span></span>
<span id="cb34-10"><a href="#cb34-10" tabindex="-1"></a><span class="va">CMQ_AUTH</span><span class="op">=</span>{{ <span class="ex">auth</span> }} R <span class="at">--no-save</span> <span class="at">--no-restore</span> <span class="at">-e</span> <span class="st">'clustermq:::worker("{{ master }}")'</span></span></code></pre></div>
<p>In this file, <code>#BSUB-*</code> defines command-line arguments to
the <code>bsub</code> program.</p>
<ul>
<li>Memory: defined by <code>BSUB-M</code> and <code>BSUB-R</code>.
Check your local setup if the memory values supplied are MiB or KiB,
default is <code>4096</code> if not requesting memory when calling
<code><a href="../reference/Q.html">Q()</a></code>
</li>
<li>Queue: <code>BSUB-q default</code>. Use the queue with name
<em>default</em>. This will most likely not exist on your system, so
choose the right name and uncomment by removing the additional
<code>#</code>
</li>
<li>Walltime: <code>BSUB-W {{ walltime }}</code>. Set the maximum time a
job is allowed to run before being killed. The default here is to
disable this line. If you enable it, enter a fixed value or pass the
<code>walltime</code> argument to each function call. The way it is
written, it will use 6 hours if no arguemnt is given.</li>
<li>For other options, see <a href="https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=bsub-options" class="external-link">the
LSF documentation</a> and add them via <code>#BSUB-*</code> (where
<code>*</code> represents the argument)</li>
<li>Do not change the identifiers in curly braces
(<code>{{ ... }}</code>), as they are used to fill in the right
variables</li>
</ul>
<p>Once this is done, the package will use your settings and no longer
warn you of the missing options.</p>
</div>
<div class="section level3">
<h3 id="sge">SGE<a class="anchor" aria-label="anchor" href="#sge"></a>
</h3>
<p>In your <code>~/.Rprofile</code> on your computing cluster, set the
following options:</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span></span>
<span>    clustermq.scheduler <span class="op">=</span> <span class="st">"sge"</span>,</span>
<span>    clustermq.template <span class="op">=</span> <span class="st">"/path/to/file/below"</span> <span class="co"># if using your own template</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The option <code>clustermq.template</code> should point to a SGE
template file like the one below (only needed if you want to supply your
own template rather than using the default).</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a><span class="co">#$ -N {{ job_name }}               # job name</span></span>
<span id="cb36-2"><a href="#cb36-2" tabindex="-1"></a><span class="co">##$ -q default                      # submit to queue named "default"</span></span>
<span id="cb36-3"><a href="#cb36-3" tabindex="-1"></a><span class="co">#$ -j y                            # combine stdout/error in one file</span></span>
<span id="cb36-4"><a href="#cb36-4" tabindex="-1"></a><span class="co">#$ -o {{ log_file | /dev/null }}   # output file</span></span>
<span id="cb36-5"><a href="#cb36-5" tabindex="-1"></a><span class="co">#$ -cwd                            # use pwd as work dir</span></span>
<span id="cb36-6"><a href="#cb36-6" tabindex="-1"></a><span class="co">#$ -V                              # use environment variable</span></span>
<span id="cb36-7"><a href="#cb36-7" tabindex="-1"></a><span class="co">#$ -t 1-{{ n_jobs }}               # submit jobs as array</span></span>
<span id="cb36-8"><a href="#cb36-8" tabindex="-1"></a><span class="co">#$ -pe smp {{ cores | 1 }}         # number of cores to use per job</span></span>
<span id="cb36-9"><a href="#cb36-9" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" tabindex="-1"></a><span class="bu">ulimit</span> <span class="at">-v</span> <span class="va">$((</span> <span class="dv">1024</span> <span class="op">*</span> <span class="er">{{</span> <span class="va">memory</span> <span class="op">|</span> <span class="dv">4096</span> }} <span class="va">))</span></span>
<span id="cb36-11"><a href="#cb36-11" tabindex="-1"></a><span class="va">CMQ_AUTH</span><span class="op">=</span>{{ <span class="ex">auth</span> }} R <span class="at">--no-save</span> <span class="at">--no-restore</span> <span class="at">-e</span> <span class="st">'clustermq:::worker("{{ master }}")'</span></span></code></pre></div>
<p>In this file, <code>#$-*</code> defines command-line arguments to the
<code>qsub</code> program.</p>
<ul>
<li>Queue: <code>$ -q default</code>. Use the queue with name
<em>default</em>. This will most likely not exist on your system, so
choose the right name and uncomment by removing the additional
<code>#</code>
</li>
<li>For other options, see <a href="https://gridscheduler.sourceforge.net/htmlman/manuals.html" class="external-link">the
SGE documentation</a>. Do not change the identifiers in curly braces
(<code>{{ ... }}</code>), as they are used to fill in the right
variables.</li>
</ul>
<p>Once this is done, the package will use your settings and no longer
warn you of the missing options.</p>
</div>
<div class="section level3">
<h3 id="slurm">SLURM<a class="anchor" aria-label="anchor" href="#slurm"></a>
</h3>
<p>In your <code>~/.Rprofile</code> on your computing cluster, set the
following options:</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span></span>
<span>    clustermq.scheduler <span class="op">=</span> <span class="st">"slurm"</span>,</span>
<span>    clustermq.template <span class="op">=</span> <span class="st">"/path/to/file/below"</span> <span class="co"># if using your own template</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The option <code>clustermq.template</code> should point to a SLURM
template file like the one below (only needed if you want to supply your
own template rather than using the default).</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb38-1"><a href="#cb38-1" tabindex="-1"></a><span class="co">#!/bin/sh</span></span>
<span id="cb38-2"><a href="#cb38-2" tabindex="-1"></a><span class="co">#SBATCH --job-name={{ job_name }}</span></span>
<span id="cb38-3"><a href="#cb38-3" tabindex="-1"></a><span class="co">##SBATCH --partition=default</span></span>
<span id="cb38-4"><a href="#cb38-4" tabindex="-1"></a><span class="co">#SBATCH --output={{ log_file | /dev/null }}</span></span>
<span id="cb38-5"><a href="#cb38-5" tabindex="-1"></a><span class="co">#SBATCH --error={{ log_file | /dev/null }}</span></span>
<span id="cb38-6"><a href="#cb38-6" tabindex="-1"></a><span class="co">#SBATCH --mem-per-cpu={{ memory | 4096 }}</span></span>
<span id="cb38-7"><a href="#cb38-7" tabindex="-1"></a><span class="co">#SBATCH --array=1-{{ n_jobs }}</span></span>
<span id="cb38-8"><a href="#cb38-8" tabindex="-1"></a><span class="co">#SBATCH --cpus-per-task={{ cores | 1 }}</span></span>
<span id="cb38-9"><a href="#cb38-9" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" tabindex="-1"></a><span class="bu">ulimit</span> <span class="at">-v</span> <span class="va">$((</span> <span class="dv">1024</span> <span class="op">*</span> <span class="er">{{</span> <span class="va">memory</span> <span class="op">|</span> <span class="dv">4096</span> }} <span class="va">))</span></span>
<span id="cb38-11"><a href="#cb38-11" tabindex="-1"></a><span class="va">CMQ_AUTH</span><span class="op">=</span>{{ <span class="ex">auth</span> }} R <span class="at">--no-save</span> <span class="at">--no-restore</span> <span class="at">-e</span> <span class="st">'clustermq:::worker("{{ master }}")'</span></span></code></pre></div>
<p>In this file, <code>#SBATCH</code> defines command-line arguments to
the <code>sbatch</code> program.</p>
<ul>
<li>Queue:
`<code>. Use the queue with name *default*. This   will most likely not exist on your system, so choose the right name (or   comment out this line with an additional</code>#`)</li>
<li>Partition: <code>SBATCH --partition default</code>. Use the queue
with name <em>default</em>. This will most likely not exist on your
system, so choose the right name and uncomment by removing the
additional <code>#</code>
</li>
<li>For other options, see <a href="https://slurm.schedmd.com/sbatch.html" class="external-link">the SLURM
documentation</a>. Do not change the identifiers in curly braces
(<code>{{ ... }}</code>), as they are used to fill in the right
variables.</li>
</ul>
<p>Once this is done, the package will use your settings and no longer
warn you of the missing options.</p>
</div>
<div class="section level3">
<h3 id="pbs">PBS<a class="anchor" aria-label="anchor" href="#pbs"></a>
</h3>
<p>In your <code>~/.Rprofile</code> on your computing cluster, set the
following options:</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span></span>
<span>    clustermq.scheduler <span class="op">=</span> <span class="st">"pbs"</span>,</span>
<span>    clustermq.template <span class="op">=</span> <span class="st">"/path/to/file/below"</span> <span class="co"># if using your own template</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The option <code>clustermq.template</code> should point to a PBS
template file like the one below (only needed if you want to supply your
own template rather than using the default).</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb40-1"><a href="#cb40-1" tabindex="-1"></a><span class="co">#PBS -N {{ job_name }}</span></span>
<span id="cb40-2"><a href="#cb40-2" tabindex="-1"></a><span class="co">#PBS -J 1-{{ n_jobs }}</span></span>
<span id="cb40-3"><a href="#cb40-3" tabindex="-1"></a><span class="co">#PBS -l select=1:ncpus={{ cores | 1 }}:mpiprocs={{ cores | 1 }}:mem={{ memory | 4096 }}MB</span></span>
<span id="cb40-4"><a href="#cb40-4" tabindex="-1"></a><span class="co">#PBS -l walltime={{ walltime | 12:00:00 }}</span></span>
<span id="cb40-5"><a href="#cb40-5" tabindex="-1"></a><span class="co">#PBS -o {{ log_file | /dev/null }}</span></span>
<span id="cb40-6"><a href="#cb40-6" tabindex="-1"></a><span class="co">#PBS -j oe</span></span>
<span id="cb40-7"><a href="#cb40-7" tabindex="-1"></a><span class="co">##PBS -q default</span></span>
<span id="cb40-8"><a href="#cb40-8" tabindex="-1"></a></span>
<span id="cb40-9"><a href="#cb40-9" tabindex="-1"></a><span class="bu">ulimit</span> <span class="at">-v</span> <span class="va">$((</span> <span class="dv">1024</span> <span class="op">*</span> <span class="er">{{</span> <span class="va">memory</span> <span class="op">|</span> <span class="dv">4096</span> }} <span class="va">))</span></span>
<span id="cb40-10"><a href="#cb40-10" tabindex="-1"></a><span class="va">CMQ_AUTH</span><span class="op">=</span>{{ <span class="ex">auth</span> }} R <span class="at">--no-save</span> <span class="at">--no-restore</span> <span class="at">-e</span> <span class="st">'clustermq:::worker("{{ master }}")'</span></span></code></pre></div>
<p>In this file, <code>#PBS-*</code> defines command-line arguments to
the <code>qsub</code> program.</p>
<ul>
<li>Queue: <code>#PBS-q default</code>. Use the queue with name
<em>default</em>. This will most likely not exist on your system, so
choose the right name and uncomment by removing the additional
<code>#</code>
</li>
<li>For other options, see the PBS documentation. Do not change the
identifiers in curly braces (<code>{{ ... }}</code>), as they are used
to fill in the right variables.</li>
</ul>
<p>Once this is done, the package will use your settings and no longer
warn you of the missing options.</p>
</div>
<div class="section level3">
<h3 id="torque">Torque<a class="anchor" aria-label="anchor" href="#torque"></a>
</h3>
<p>In your <code>~/.Rprofile</code> on your computing cluster, set the
following options:</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>clustermq.scheduler <span class="op">=</span> <span class="st">"Torque"</span>,</span>
<span>        clustermq.template <span class="op">=</span> <span class="st">"/path/to/file/below"</span> <span class="co"># if using your own template</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The option <code>clustermq.template</code> should point to a Torque
template file like the one below (only needed if you want to supply your
own template rather than using the default).</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb42-1"><a href="#cb42-1" tabindex="-1"></a><span class="co">#PBS -N {{ job_name }}</span></span>
<span id="cb42-2"><a href="#cb42-2" tabindex="-1"></a><span class="co">#PBS -l nodes={{ n_jobs }}:ppn={{ cores | 1 }},walltime={{ walltime | 12:00:00 }}</span></span>
<span id="cb42-3"><a href="#cb42-3" tabindex="-1"></a><span class="co">#PBS -o {{ log_file | /dev/null }}</span></span>
<span id="cb42-4"><a href="#cb42-4" tabindex="-1"></a><span class="co">#PBS -j oe</span></span>
<span id="cb42-5"><a href="#cb42-5" tabindex="-1"></a><span class="co">##PBS -q default</span></span>
<span id="cb42-6"><a href="#cb42-6" tabindex="-1"></a></span>
<span id="cb42-7"><a href="#cb42-7" tabindex="-1"></a><span class="bu">ulimit</span> <span class="at">-v</span> <span class="va">$((</span> <span class="dv">1024</span> <span class="op">*</span> <span class="er">{{</span> <span class="va">memory</span> <span class="op">|</span> <span class="dv">4096</span> }} <span class="va">))</span></span>
<span id="cb42-8"><a href="#cb42-8" tabindex="-1"></a><span class="va">CMQ_AUTH</span><span class="op">=</span>{{ <span class="ex">auth</span> }} R <span class="at">--no-save</span> <span class="at">--no-restore</span> <span class="at">-e</span> <span class="st">'clustermq:::worker("{{ master }}")'</span></span></code></pre></div>
<p>In this file, <code>#PBS-*</code> defines command-line arguments to
the <code>qsub</code> program.</p>
<ul>
<li>Queue: <code>#PBS-q default</code>. Use the queue with name
<em>default</em>. This will most likely not exist on your system, so
choose the right name and uncomment by removing the additional
<code>#</code>
</li>
<li>For other options, see the Torque documentation. Do not change the
identifiers in curly braces (<code>{{ ... }}</code>), as they are used
to fill in the right variables.</li>
</ul>
<p>Once this is done, the package will use your settings and no longer
warn you of the missing options.</p>
</div>
<div class="section level3">
<h3 id="ssh-template">SSH<a class="anchor" aria-label="anchor" href="#ssh-template"></a>
</h3>
<p>While SSH is not a scheduler, we can access remote schedulers via
SSH. If you want to use it, first make sure that your real scheduler is
running when manually connecting to the HPC environment.</p>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>clustermq.scheduler <span class="op">=</span> <span class="st">"ssh"</span>,</span>
<span>        clustermq.ssh.host <span class="op">=</span> <span class="st">"myhost"</span>, <span class="co"># set this up in your local ~/.ssh/config</span></span>
<span>        clustermq.ssh.log <span class="op">=</span> <span class="st">"~/ssh_proxy.log"</span>, <span class="co"># log file on your HPC</span></span>
<span>        clustermq.ssh.timeout <span class="op">=</span> <span class="fl">30</span>, <span class="co"># if changing the default connection timeout</span></span>
<span>        clustermq.template <span class="op">=</span> <span class="st">"/path/to/file/below"</span> <span class="co"># if using your own template</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The default template is shown below. If <code>R</code> is not in your
HPC <code>$PATH</code>, you may need to specify its path or <a href="https://github.com/mschubert/clustermq/issues/281" class="external-link">load the
required bash modules/conda environments</a>.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb44-1"><a href="#cb44-1" tabindex="-1"></a><span class="fu">ssh</span> <span class="at">-o</span> <span class="st">"ExitOnForwardFailure yes"</span> <span class="at">-f</span> <span class="dt">\</span></span>
<span id="cb44-2"><a href="#cb44-2" tabindex="-1"></a>    <span class="at">-R</span> {{ ctl_port }}:localhost:{{ local_port }} <span class="dt">\</span></span>
<span id="cb44-3"><a href="#cb44-3" tabindex="-1"></a>    <span class="at">-R</span> {{ job_port }}:localhost:{{ fwd_port }} <span class="dt">\</span></span>
<span id="cb44-4"><a href="#cb44-4" tabindex="-1"></a>    {{ ssh_host }} <span class="dt">\</span></span>
<span id="cb44-5"><a href="#cb44-5" tabindex="-1"></a>    <span class="st">"R --no-save --no-restore -e </span><span class="dt">\</span></span>
<span id="cb44-6"><a href="#cb44-6" tabindex="-1"></a><span class="st">        'clustermq:::ssh_proxy(ctl={{ ctl_port }}, job={{ job_port }})' </span><span class="dt">\</span></span>
<span id="cb44-7"><a href="#cb44-7" tabindex="-1"></a><span class="st">        &gt; {{ ssh_log | /dev/null }} 2&gt;&amp;1"</span></span></code></pre></div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Michael Schubert, ZeroMQ authors.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
